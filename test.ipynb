{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649cc677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Debugging LangGraph API ===\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Debug your LangGraph API\n",
    "BASE_URL = \"http://127.0.0.1:2024\"\n",
    "\n",
    "# First, let's check what's available\n",
    "print(\"=== Debugging LangGraph API ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "433e6149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Checking OpenAPI schema...\n",
      "✅ Available endpoints: ['/assistants', '/assistants/search', '/assistants/{assistant_id}', '/assistants/{assistant_id}/graph', '/assistants/{assistant_id}/subgraphs', '/assistants/{assistant_id}/subgraphs/{namespace}', '/assistants/{assistant_id}/schemas', '/assistants/{assistant_id}/versions', '/assistants/{assistant_id}/latest', '/threads', '/threads/search', '/threads/{thread_id}/state', '/threads/{thread_id}/state/{checkpoint_id}', '/threads/{thread_id}/state/checkpoint', '/threads/{thread_id}/history', '/threads/{thread_id}/copy', '/threads/{thread_id}', '/threads/{thread_id}/runs', '/threads/{thread_id}/runs/crons', '/threads/{thread_id}/runs/stream', '/threads/{thread_id}/runs/wait', '/threads/{thread_id}/runs/{run_id}', '/threads/{thread_id}/runs/{run_id}/join', '/threads/{thread_id}/runs/{run_id}/stream', '/threads/{thread_id}/runs/{run_id}/cancel', '/runs/crons', '/runs/crons/search', '/runs/stream', '/runs/cancel', '/runs/wait', '/runs', '/runs/batch', '/runs/crons/{cron_id}', '/store/items', '/store/items/search', '/store/namespaces', '/mcp/']\n"
     ]
    }
   ],
   "source": [
    "# 2. Check available endpoints\n",
    "try:\n",
    "    print(\"\\n2. Checking OpenAPI schema...\")\n",
    "    response = requests.get(f\"{BASE_URL}/openapi.json\")\n",
    "    if response.status_code == 200:\n",
    "        openapi = response.json()\n",
    "        paths = list(openapi.get('paths', {}).keys())\n",
    "        print(f\"✅ Available endpoints: {paths}\")\n",
    "    else:\n",
    "        print(f\"⚠️  OpenAPI not available (status: {response.status_code})\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Could not get OpenAPI: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb6ebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: POST with empty JSON...\n",
      "Status: 200\n",
      "✅ Success: {'thread_id': '96c24d82-793b-4f6e-ad0c-5b6833bf5eaf', 'created_at': '2025-06-07T02:45:25.419957+00:00', 'updated_at': '2025-06-07T02:45:25.419957+00:00', 'metadata': {}, 'status': 'idle', 'config': {}, 'values': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'96c24d82-793b-4f6e-ad0c-5b6833bf5eaf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1: POST with empty JSON body\n",
    "try:\n",
    "    print(\"Method 1: POST with empty JSON...\")\n",
    "    response = requests.post(f\"{BASE_URL}/threads\", json={})\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✅ Success: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"❌ Failed: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "thread_id = response.json().get(\"thread_id\")\n",
    "thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d7aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"topic\": \"AI in education\",\n",
    "    \"max_analysts\": 3,\n",
    "    # \"human_analyst_feedback\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14986d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Assistant created: deb9843e-abbd-4628-a2e3-58d4c249b705\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\"http://127.0.0.1:2024/assistants\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": \"\",\n",
    "      \"graph_id\": \"create_analysts\",\n",
    "      \"config\": {},\n",
    "      \"metadata\": {},\n",
    "      \"if_exists\": \"raise\",\n",
    "      \"name\": \"\",\n",
    "      \"description\": \"null\"\n",
    "    }\n",
    ")\n",
    "assistant_id = response.json()[\"assistant_id\"]\n",
    "print(f\"✅ Assistant created: {assistant_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e51af7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run wait response: {'topic': 'AI in education', 'max_analysts': 3, 'human_analyst_feedback': [], 'analysts': [{'affiliation': 'University of California, Berkeley', 'name': 'Dr. Anya Sharma', 'role': 'Ethical AI in Education Specialist', 'description': 'Focuses on the ethical implications of AI in education, particularly concerning data privacy, algorithmic bias, and equitable access to AI-powered tools. Concerned about the potential for AI to exacerbate existing inequalities in education and advocates for responsible AI development and deployment.'}, {'affiliation': 'Pearson Education', 'name': 'Mr. Ben Carter', 'role': 'AI Education Technology Strategist', 'description': 'Focused on the practical applications of AI to improve educational outcomes, such as personalized learning platforms, automated assessment tools, and AI-driven tutoring systems. Motivated by the potential to enhance student engagement, improve teacher effectiveness, and expand access to quality education. '}, {'affiliation': 'Stanford Research Institute', 'name': 'Dr. Chen Wei', 'role': 'Future of Education Researcher', 'description': 'Investigates the long-term societal impacts of AI in education, including the changing role of teachers, the future of work, and the skills needed for students to thrive in an AI-driven world. Concerned about preparing students for the future and ensuring that education systems adapt to technological advancements.'}]}\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(\n",
    "    f\"http://127.0.0.1:2024/threads/{thread_id}/runs/wait\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": f\"{assistant_id}\",\n",
    "      \"input\": input_data,\n",
    "      },\n",
    ")\n",
    "print(f\"Run wait response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09ad2265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run wait response: {'topic': 'AI in education', 'max_analysts': 3, 'human_analyst_feedback': ['add analysts from goverment'], 'analysts': [{'affiliation': 'University of California, Berkeley', 'name': 'Dr. Anya Sharma', 'role': 'Ethical AI in Education Specialist', 'description': 'Focuses on the ethical implications of AI in education, particularly concerning data privacy, algorithmic bias, and equitable access to AI-powered tools. Concerned about the potential for AI to exacerbate existing inequalities in education and advocates for responsible AI development and deployment.'}, {'affiliation': 'Pearson Education', 'name': 'Mr. Ben Carter', 'role': 'AI Education Technology Strategist', 'description': 'Focused on the practical applications of AI to improve educational outcomes, such as personalized learning platforms, automated assessment tools, and AI-driven tutoring systems. Motivated by the potential to enhance student engagement, improve teacher effectiveness, and expand access to quality education. '}, {'affiliation': 'Stanford Research Institute', 'name': 'Dr. Chen Wei', 'role': 'Future of Education Researcher', 'description': 'Investigates the long-term societal impacts of AI in education, including the changing role of teachers, the future of work, and the skills needed for students to thrive in an AI-driven world. Concerned about preparing students for the future and ensuring that education systems adapt to technological advancements.'}, {'affiliation': 'Government', 'name': 'Dr. Eleanor Vance', 'role': 'Policy Analyst', 'description': 'Focuses on the ethical implications and societal impact of AI in education, ensuring fairness, and data privacy. They are concerned with how AI can be used responsibly to improve educational outcomes while mitigating potential risks.'}, {'affiliation': 'Educational Institution', 'name': 'Professor Anya Sharma', 'role': 'Educational Technologist', 'description': 'Analyzes the integration of AI tools in the classroom, evaluating their effectiveness in enhancing student learning and teacher productivity. They are motivated by improving educational practices and outcomes. '}, {'affiliation': 'Technology Company', 'name': 'David Chen', 'role': 'Product Manager', 'description': 'Examines the market for AI-driven educational tools, focusing on innovation, user experience, and scalability. They are driven by the opportunity to develop and deploy cutting-edge educational solutions.'}]}\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"human_analyst_feedback\": [\"add analysts from goverment\"]\n",
    "}\n",
    "response = requests.post(\n",
    "    f\"http://127.0.0.1:2024/threads/{thread_id}/runs/wait\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": f\"{assistant_id}\",\n",
    "      \"command\": {\n",
    "        \"update\": input_data,\n",
    "        \"resume\": input_data,\n",
    "        }\n",
    "      },\n",
    ")\n",
    "print(f\"Run wait response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6cfb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'AI in education', 'max_analysts': 3, 'human_analyst_feedback': ['add analysts from goverment'], 'analysts': [{'affiliation': 'University of California, Berkeley', 'name': 'Dr. Anya Sharma', 'role': 'Ethical AI in Education Specialist', 'description': 'Focuses on the ethical implications of AI in education, particularly concerning data privacy, algorithmic bias, and equitable access to AI-powered tools. Concerned about the potential for AI to exacerbate existing inequalities in education and advocates for responsible AI development and deployment.'}, {'affiliation': 'Pearson Education', 'name': 'Mr. Ben Carter', 'role': 'AI Education Technology Strategist', 'description': 'Focused on the practical applications of AI to improve educational outcomes, such as personalized learning platforms, automated assessment tools, and AI-driven tutoring systems. Motivated by the potential to enhance student engagement, improve teacher effectiveness, and expand access to quality education. '}, {'affiliation': 'Stanford Research Institute', 'name': 'Dr. Chen Wei', 'role': 'Future of Education Researcher', 'description': 'Investigates the long-term societal impacts of AI in education, including the changing role of teachers, the future of work, and the skills needed for students to thrive in an AI-driven world. Concerned about preparing students for the future and ensuring that education systems adapt to technological advancements.'}, {'affiliation': 'Government', 'name': 'Dr. Eleanor Vance', 'role': 'Policy Analyst', 'description': 'Focuses on the ethical implications and societal impact of AI in education, ensuring fairness, and data privacy. They are concerned with how AI can be used responsibly to improve educational outcomes while mitigating potential risks.'}, {'affiliation': 'Educational Institution', 'name': 'Professor Anya Sharma', 'role': 'Educational Technologist', 'description': 'Analyzes the integration of AI tools in the classroom, evaluating their effectiveness in enhancing student learning and teacher productivity. They are motivated by improving educational practices and outcomes. '}, {'affiliation': 'Technology Company', 'name': 'David Chen', 'role': 'Product Manager', 'description': 'Examines the market for AI-driven educational tools, focusing on innovation, user experience, and scalability. They are driven by the opportunity to develop and deploy cutting-edge educational solutions.'}]}\n"
     ]
    }
   ],
   "source": [
    "state = requests.get(\n",
    "    f\"http://127.0.0.1:2024/threads/{thread_id}/state\"\n",
    ")\n",
    "print(state.json()[\"values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71488321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['values', 'next', 'tasks', 'metadata', 'created_at', 'checkpoint', 'parent_checkpoint', 'checkpoint_id', 'parent_checkpoint_id'])\n"
     ]
    }
   ],
   "source": [
    "state_json = state.json()\n",
    "print(state_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e11ac13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run wait response: {'topic': 'AI in education', 'max_analysts': 3, 'human_analyst_feedback': ['add analysts from goverment', 'approved'], 'analysts': [{'affiliation': 'University of Innovation', 'name': 'Dr. Anya Sharma', 'role': 'AI Implementation Specialist', 'description': 'Focuses on the practical application of AI in classrooms, emphasizing tools for personalized learning and automated grading. Concerned with equitable access and effective implementation.'}, {'affiliation': 'Ethical AI Watchdog', 'name': 'Ms. Evelyn Reed', 'role': 'AI Ethics Analyst', 'description': 'Primarily concerned with data privacy, algorithmic bias, and the ethical implications of AI in education. Advocates for responsible AI development and deployment.'}, {'affiliation': 'Global Education Consortium', 'name': 'Mr. Ben Carter', 'role': 'Education Economist', 'description': 'Analyzes the economic impact of AI on education systems, including cost-benefit analysis of AI tools, investment trends, and the future of the education workforce.'}, {'affiliation': 'Government', 'name': 'Dr. Evelyn Reed', 'role': 'Policy Analyst', 'description': 'Focuses on the ethical implications of AI in education, data privacy, and ensuring equitable access to AI-powered educational tools. Concerned with policy implications, regulatory frameworks, and the responsible deployment of AI technologies to avoid bias and discrimination.'}, {'affiliation': 'Educational Institution', 'name': 'Professor Anya Sharma', 'role': 'Educational Researcher', 'description': 'Investigates the integration of AI in curriculum design, personalized learning experiences, and assessment methods. Focuses on improving student outcomes, teacher training in AI-related skills, and the impact of AI on educational methodologies. Concerned with the practical application of AI in the classroom.'}, {'affiliation': 'Technology Company', 'name': 'Mr. Ben Carter', 'role': 'Product Manager', 'description': 'Examines the development and market potential of AI-driven educational products and services. Focuses on technological advancements, user experience, and the competitive landscape of AI in education. Concerned with innovation, market trends, and the commercial viability of AI solutions.'}], 'final_analysts': [{'affiliation': 'University of Innovation', 'name': 'Dr. Anya Sharma', 'role': 'AI Implementation Specialist', 'description': 'Focuses on the practical application of AI in classrooms, emphasizing tools for personalized learning and automated grading. Concerned with equitable access and effective implementation.'}, {'affiliation': 'Ethical AI Watchdog', 'name': 'Ms. Evelyn Reed', 'role': 'AI Ethics Analyst', 'description': 'Primarily concerned with data privacy, algorithmic bias, and the ethical implications of AI in education. Advocates for responsible AI development and deployment.'}, {'affiliation': 'Government', 'name': 'Dr. Evelyn Reed', 'role': 'Policy Analyst', 'description': 'Focuses on the ethical implications of AI in education, data privacy, and ensuring equitable access to AI-powered educational tools. Concerned with policy implications, regulatory frameworks, and the responsible deployment of AI technologies to avoid bias and discrimination.'}]}\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"human_analyst_feedback\": [\"approved\"]\n",
    "}\n",
    "response = requests.post(\n",
    "    f\"http://127.0.0.1:2024/threads/{thread_id}/runs/wait\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": f\"{assistant_id}\",\n",
    "      # \"input\": input_data,\n",
    "      \"command\": {\n",
    "        \"update\": input_data,\n",
    "        \"resume\": input_data,\n",
    "        # \"goto\": {\n",
    "        #   \"node\": \"human_feedback\",\n",
    "        #   \"input\": input_data\n",
    "        # }\n",
    "      },\n",
    "    }\n",
    ")\n",
    "print(f\"Run wait response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80ac970b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: POST with empty JSON...\n",
      "Status: 200\n",
      "✅ Success: {'thread_id': 'd48f2d86-d2e3-4d35-8a4f-775ce5b6a5db', 'created_at': '2025-06-05T06:14:21.726465+00:00', 'updated_at': '2025-06-05T06:14:21.726465+00:00', 'metadata': {}, 'status': 'idle', 'config': {}, 'values': None}\n",
      "d48f2d86-d2e3-4d35-8a4f-775ce5b6a5db\n",
      "✅ Assistant created: edd21f09-10d3-4781-8d4b-250b6bf3f26d\n"
     ]
    }
   ],
   "source": [
    "# Method 1: POST with empty JSON body\n",
    "try:\n",
    "    print(\"Method 1: POST with empty JSON...\")\n",
    "    response = requests.post(f\"{BASE_URL}/threads\", json={})\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✅ Success: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"❌ Failed: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "thread_id = response.json().get(\"thread_id\")\n",
    "print(thread_id)\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:2024/assistants\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": \"\",\n",
    "      \"graph_id\": \"conduct_interviews\",\n",
    "      \"config\": {},\n",
    "      \"metadata\": {},\n",
    "      \"if_exists\": \"raise\",\n",
    "      \"name\": \"\",\n",
    "      \"description\": \"null\"\n",
    "    }\n",
    ")\n",
    "assistant_id = response.json()[\"assistant_id\"]\n",
    "print(f\"✅ Assistant created: {assistant_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20bf071a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run wait response: {'messages': [{'content': '', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '8d5832e6-5767-49cf-88b2-cd2468cebec7', 'example': False}, {'content': 'Ask questions', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'd2e96240-8b41-41db-a11b-bfdf56c21339', 'example': False}, {'content': \"Hello Dr. Sterling, my name is Alex Reynolds, and I'm an AI analyst. I'm fascinated by the ethical dimensions of AI, especially concerning frameworks like LangGraph. My primary goal is to understand the specific challenges and potential pitfalls in deploying these technologies responsibly.\\n\\nMy first question for you is: **Could you provide a concrete example of a privacy risk that might arise from the use of LangGraph, and how that risk could manifest in a real-world scenario?**\", 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--ff9693da-cfd1-4aa4-a87e-b591e4e8678e-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 242, 'output_tokens': 99, 'total_tokens': 341, 'input_token_details': {'cache_read': 0}}}], 'context': []}\n"
     ]
    }
   ],
   "source": [
    "input_data = {\n",
    "    # \"topic\": \"AI in education\",\n",
    "    \"messages\": [\"Ask questions\"],\n",
    "    # \"human_analyst_feedback\": []\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"http://127.0.0.1:2024/threads/{thread_id}/runs/wait\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": f\"{assistant_id}\",\n",
    "      \"input\": input_data,\n",
    "      },\n",
    ")\n",
    "print(f\"Run wait response: {response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b1670fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Dr. Sterling, my name is Alex Reynolds, and I'm an AI analyst. I'm fascinated by the ethical dimensions of AI, especially concerning frameworks like LangGraph. My primary goal is to understand the specific challenges and potential pitfalls in deploying these technologies responsibly.\n",
      "\n",
      "My first question for you is: **Could you provide a concrete example of a privacy risk that might arise from the use of LangGraph, and how that risk could manifest in a real-world scenario?**\n"
     ]
    }
   ],
   "source": [
    "rjson = response.json()\n",
    "print(rjson[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16afba93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m client\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# async for chunk in client.runs.stream(thread['thread_id'], agent['assistant_id'], input=input):\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#     print(chunk)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mruns(thread[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthread_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43magent\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistant_id\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(chunk)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent' is not defined"
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=BASE_URL)\n",
    "assistant = await client.assistants.create(\"conduct_interviews\")\n",
    "# agent = assistants[0]\n",
    "thread = await client.threads.create()\n",
    "# async for chunk in client.runs.stream(thread['thread_id'], agent['assistant_id'], input=input):\n",
    "#     print(chunk)\n",
    "for chunk in client.runs(thread['thread_id'], agent['assistant_id'], input=input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b78cc5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'assistant_id': '26f5bfb8-750b-4f12-90b2-42cfbf061b04', 'graph_id': 'conduct_interviews', 'config': {}, 'metadata': {}, 'name': 'Untitled', 'created_at': '2025-06-05T06:41:08.257301+00:00', 'updated_at': '2025-06-05T06:41:08.257301+00:00', 'version': 1, 'description': 'null'}, {'assistant_id': 'be2cf8ca-6f5b-471d-b693-281bfe9dfaaa', 'graph_id': 'conduct_interviews', 'config': {}, 'metadata': {}, 'name': 'Untitled', 'created_at': '2025-06-05T06:38:54.853754+00:00', 'updated_at': '2025-06-05T06:38:54.853754+00:00', 'version': 1, 'description': 'null'}, {'assistant_id': '91c912ff-e90a-4fa8-9726-0e358c71dea6', 'graph_id': 'conduct_interviews', 'config': {}, 'metadata': {}, 'name': 'Untitled', 'created_at': '2025-06-05T06:37:56.703796+00:00', 'updated_at': '2025-06-05T06:37:56.703796+00:00', 'version': 1, 'description': 'null'}, {'assistant_id': 'edd21f09-10d3-4781-8d4b-250b6bf3f26d', 'graph_id': 'conduct_interviews', 'config': {}, 'metadata': {}, 'name': 'Untitled', 'created_at': '2025-06-05T06:14:21.736038+00:00', 'updated_at': '2025-06-05T06:14:21.736038+00:00', 'version': 1, 'description': 'null'}, {'assistant_id': '12d61b2c-15a5-5d4f-92ae-fd4d39363372', 'graph_id': 'conduct_interviews', 'config': {}, 'metadata': {'created_by': 'system'}, 'name': 'conduct_interviews', 'created_at': '2025-06-05T03:02:53.050963+00:00', 'updated_at': '2025-06-05T03:02:53.050963+00:00', 'version': 1, 'description': None}, {'assistant_id': '15463b19-397a-51d0-8a78-62a529b05340', 'graph_id': 'create_analysts', 'config': {}, 'metadata': {'created_by': 'system'}, 'name': 'create_analysts', 'created_at': '2025-06-05T03:02:53.050444+00:00', 'updated_at': '2025-06-05T03:02:53.050444+00:00', 'version': 1, 'description': None}]\n"
     ]
    }
   ],
   "source": [
    "print(assistants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9f0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client(url=BASE_URL)\n",
    "assistant = await client.assistants.create(\"conduct_interviews\")\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(thread['thread_id'], assistant['assistant_id'], input=input_data):\n",
    "    print(chunk)\n",
    "\n",
    "# chunk = await client.runs.wait(thread['thread_id'], assistant['assistant_id'], input=input_data)\n",
    "# print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "062829b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1: POST with empty JSON...\n",
      "Status: 200\n",
      "✅ Success: {'thread_id': '0b7225a9-906a-47cd-96c5-9de3b3cf8191', 'created_at': '2025-06-06T02:00:06.485958+00:00', 'updated_at': '2025-06-06T02:00:06.485958+00:00', 'metadata': {}, 'status': 'idle', 'config': {}, 'values': None}\n",
      "0b7225a9-906a-47cd-96c5-9de3b3cf8191\n",
      "✅ Assistant created: 1a8fd959-6ff4-45c4-8a43-c8a103e261d9\n",
      "🔹 Raw Line: event: metadata\n",
      "🔹 Raw Line: data: {\"run_id\":\"1f04279f-7d75-6c9b-9585-34d110174bb4\",\"attempt\":1}\n",
      "🔹 Raw Line: id: 0\n",
      "🔹 Raw Line: event: updates\n",
      "🔹 Raw Line: data: {\"generate_question\":{\"messages\":[{\"content\":\"Hello, I'm John Doe, a climate scientist at the Global Climate Institute. I'm eager to learn more about the intricacies of climate modeling and policy analysis.\\n\\nMy first question is: What are the most significant challenges in accurately modeling the impact of cloud formation on future climate projections, and why are these challenges so persistent?\",\"additional_kwargs\":{},\"response_metadata\":{\"prompt_feedback\":{\"block_reason\":0,\"safety_ratings\":[]},\"finish_reason\":\"STOP\",\"safety_ratings\":[]},\"type\":\"ai\",\"name\":null,\"id\":\"run--e7345085-38ab-4970-bdc3-e1215cf56c4a-0\",\"example\":false,\"tool_calls\":[],\"invalid_tool_calls\":[],\"usage_metadata\":{\"input_tokens\":229,\"output_tokens\":68,\"total_tokens\":297,\"input_token_details\":{\"cache_read\":0}}}]}}\n",
      "🔹 Raw Line: id: 1\n",
      "🔹 Raw Line: : heartbeat\n",
      "🔹 Raw Line: : heartbeat\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 76\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔹 Raw Line: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;66;03m# if line.startswith(\"data:\"):\u001b[39;00m\n\u001b[0;32m     71\u001b[0m             \u001b[38;5;66;03m#     data = line[len(\"data:\"):].strip()\u001b[39;00m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;66;03m#     print(f\"📥 Event Data: {data}\")\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# input_data = {\"question\": \"Can you help me with a mock interview?\"}\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m \u001b[43mrun_graph_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 64\u001b[0m, in \u001b[0;36mrun_graph_stream\u001b[1;34m(input_data)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Stream request failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# skip empty lines\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\requests\\utils.py:572\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    571\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    573\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\urllib3\\response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\urllib3\\response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\urllib3\\response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\IdeaPad\\anaconda3\\envs\\pytorch\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Method 1: POST with empty JSON body\n",
    "try:\n",
    "    print(\"Method 1: POST with empty JSON...\")\n",
    "    response = requests.post(f\"{BASE_URL}/threads\", json={})\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(f\"✅ Success: {response.json()}\")\n",
    "    else:\n",
    "        print(f\"❌ Failed: {response.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "\n",
    "thread_id = response.json().get(\"thread_id\")\n",
    "print(thread_id)\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:2024/assistants\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"assistant_id\": \"\",\n",
    "      \"graph_id\": \"conduct_interviews\",\n",
    "      \"config\": {},\n",
    "      \"metadata\": {},\n",
    "      \"if_exists\": \"raise\",\n",
    "      \"name\": \"\",\n",
    "      \"description\": \"null\"\n",
    "    }\n",
    ")\n",
    "assistant_id = response.json()[\"assistant_id\"]\n",
    "print(f\"✅ Assistant created: {assistant_id}\")\n",
    "\n",
    "analyst = {\n",
    "    \"name\":\"John Doe\",\n",
    "    \"role\":\"Climate Scientist\",\n",
    "    \"affiliation\":\"Global Climate Institute\",\n",
    "    \"description\":\"Expert in climate modeling and policy analysis.\",\n",
    "}\n",
    "\n",
    "input_data = {\n",
    "    # \"topic\": \"AI in education\",\n",
    "    # \"messages\": [HumanMessage(f\"Considering your expertise, ask your first question about climate change?\")],\n",
    "    # \"human_analyst_feedback\": [],\n",
    "    \"topic\": \"climate change\",\n",
    "    \"analyst\": analyst,\n",
    "}\n",
    "\n",
    "def run_graph_stream(input_data):\n",
    "    url = f\"{BASE_URL}/threads/{thread_id}/runs/stream\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"assistant_id\": assistant_id,\n",
    "        \"input\": input_data,\n",
    "        \"stream_mode\": [\"updates\"],\n",
    "    }\n",
    "\n",
    "    with requests.post(url, headers=headers, json=payload, stream=True) as response:\n",
    "        if response.status_code != 200:\n",
    "            print(f\"❌ Stream request failed: {response.status_code} - {response.text}\")\n",
    "            return\n",
    "\n",
    "        for line in response.iter_lines(decode_unicode=True):\n",
    "            if line.strip() == \"\":\n",
    "                continue  # skip empty lines\n",
    "\n",
    "            print(f\"🔹 Raw Line: {line}\")\n",
    "            \n",
    "            # if line.startswith(\"data:\"):\n",
    "            #     data = line[len(\"data:\"):].strip()\n",
    "            #     print(f\"📥 Event Data: {data}\")\n",
    "\n",
    "# Example usage\n",
    "# input_data = {\"question\": \"Can you help me with a mock interview?\"}\n",
    "run_graph_stream(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c734ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [], 'google_api_key': 'AIzaSyDKr22mO6Wt9xfKWK1_AOgbkgKNqHV1ydg', 'tavily_api_key': '', 'topic': 'climate change', 'max_analysts': 3, 'human_analyst_feedback': [], 'analysts': [Analyst(affiliation='Environmental Research Institute', name='Dr. Anya Sharma', role='Ecosystems Impact Analyst', description='Focuses on the impact of climate change on global ecosystems, advocating for conservation and sustainable practices.'), Analyst(affiliation='Renewable Energy Association', name='Mr. Ben Carter', role='Energy Transition Analyst', description='Driven by the economic opportunities of renewable energy sources, analyzing the transition from fossil fuels and investment potential.'), Analyst(affiliation='Global Economics Forum', name='Ms. Chloe Davis', role='Climate Economics Analyst', description='Concerned with the economic consequences of climate change, including market risks, policy impacts, and financial investments.')], 'sections': []}\n",
      "{'messages': [], 'google_api_key': 'AIzaSyDKr22mO6Wt9xfKWK1_AOgbkgKNqHV1ydg', 'tavily_api_key': '', 'topic': 'climate change', 'max_analysts': 3, 'human_analyst_feedback': [], 'analysts': [Analyst(affiliation='Environmental Research Institute', name='Dr. Anya Sharma', role='Ecosystems Impact Analyst', description='Focuses on the impact of climate change on global ecosystems, advocating for conservation and sustainable practices.'), Analyst(affiliation='Renewable Energy Association', name='Mr. Ben Carter', role='Energy Transition Analyst', description='Driven by the economic opportunities of renewable energy sources, analyzing the transition from fossil fuels and investment potential.'), Analyst(affiliation='Global Economics Forum', name='Ms. Chloe Davis', role='Climate Economics Analyst', description='Concerned with the economic consequences of climate change, including market risks, policy impacts, and financial investments.')], 'sections': []}\n"
     ]
    }
   ],
   "source": [
    "from graph import graph_memory\n",
    "import uuid\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "input_data = {\n",
    "                \"topic\": \"climate change\",\n",
    "                \"max_analysts\": 3,\n",
    "                \"google_api_key\": 'AIzaSyDKr22mO6Wt9xfKWK1_AOgbkgKNqHV1ydg',\n",
    "                \"tavily_api_key\": '',\n",
    "            }\n",
    "response = graph_memory.invoke(input_data, thread)\n",
    "print(response)\n",
    "\n",
    "state_data = graph_memory.get_state(thread)[0]\n",
    "print(state_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
